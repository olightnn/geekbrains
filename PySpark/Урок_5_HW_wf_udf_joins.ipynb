{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W5AsCKO5Nqsh",
    "outputId": "7358d0fd-8120-49c4-b7ad-9724691bdf99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 212.4 MB 88 kB/s \n",
      "\u001b[?25hCollecting py4j==0.10.9\n",
      "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
      "\u001b[K     |████████████████████████████████| 198 kB 58.1 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=0e928c8f788e469b360ecaa4eac3ecc68f5e5d9a3037e3ae3818171922736070\n",
      "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "E3Q9g_UyNxS6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/08/17 06:24:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder\\\n",
    "    .master(\"local[2]\")\\\n",
    "    .appName(\"Lesson_2\")\\\n",
    "    .config(\"spark.executor.instances\",2)\\\n",
    "    .config(\"spark.executor.memory\",'2g')\\\n",
    "    .config(\"spark.executor.cores\",1)\\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVGNGR7pN1KC"
   },
   "source": [
    "# Самостоятельная работа к уроку 3\n",
    "На уроке мы попробовали оконные и пользовательские функции. Теперь закрепим полученные знания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agigNChqOHnK"
   },
   "source": [
    "## Данные: [google drive: raw_sales.csv](https://drive.google.com/file/d/1G2N7Mnt4-Tqz4JdJxutGDMbJiOr32kZp/view?usp=sharing)\n",
    "\n",
    " Каждая строчка это продажа жилья, которая состоит из следующих полей (думаю описание не требуется):\n",
    "*   date of sale\n",
    "*   price\n",
    "*   property type\n",
    "*   number of bedrooms\n",
    "*   4digit postcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xisyFowtQgx-"
   },
   "source": [
    "## Задание 1\n",
    "Добавьте к таблице следующие поля:\n",
    "*  Средняя стоимость 10 проданных домов до текущего в том же районе (4digit postcode) (1 балл)\n",
    "*  Средняя стоимость 10 проданных домов после текущего в том же районе (4digit postcode) (1 балл)\n",
    "*  Стоимость последнего проданного дома до текущего (1 балл)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NsUKEiRTUOtT"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_df = StructType(\n",
    "    [\n",
    "        StructField('datesold', DateType(), True),\n",
    "        StructField('postcode', IntegerType(), True),\n",
    "        StructField('price', IntegerType(), True),\n",
    "        StructField('propertyType', StringType(), True),\n",
    "        StructField('bedrooms', IntegerType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "df = spark.read.format('csv').schema(schema_df).option('header', 'True').load('raw_sales.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+------------+--------+\n",
      "|  datesold|postcode|  price|propertyType|bedrooms|\n",
      "+----------+--------+-------+------------+--------+\n",
      "|2007-02-07|    2607| 525000|       house|       4|\n",
      "|2007-02-27|    2906| 290000|       house|       3|\n",
      "|2007-03-07|    2905| 328000|       house|       3|\n",
      "|2007-03-09|    2905| 380000|       house|       4|\n",
      "|2007-03-21|    2906| 310000|       house|       3|\n",
      "|2007-04-04|    2905| 465000|       house|       4|\n",
      "|2007-04-24|    2607| 399000|       house|       3|\n",
      "|2007-04-30|    2606|1530000|       house|       4|\n",
      "|2007-05-24|    2902| 359000|       house|       3|\n",
      "|2007-05-25|    2906| 320000|       house|       3|\n",
      "|2007-06-26|    2902| 385000|       house|       3|\n",
      "|2007-06-27|    2906| 305000|       house|       3|\n",
      "|2007-06-27|    2612| 850000|       house|       4|\n",
      "|2007-06-28|    2904| 765000|       house|       4|\n",
      "|2007-06-30|    2615| 517000|       house|       4|\n",
      "|2007-07-02|    2914| 800000|       house|       5|\n",
      "|2007-07-03|    2906| 336000|       house|       3|\n",
      "|2007-07-06|    2615| 535000|       house|       5|\n",
      "|2007-07-07|    2602| 900000|       house|       4|\n",
      "|2007-07-08|    2600| 327000|       house|       1|\n",
      "+----------+--------+-------+------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df.printSchema()\n",
    "df.registerTempTable('df')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+------------+--------+-------------+\n",
      "|  datesold|postcode| price|propertyType|bedrooms|avg_pr_before|\n",
      "+----------+--------+------+------------+--------+-------------+\n",
      "|2007-07-02|    2914|800000|       house|       5|     800000.0|\n",
      "|2008-06-17|    2914|600000|       house|       4|     700000.0|\n",
      "|2008-08-29|    2914|465000|       house|       4|    621666.67|\n",
      "|2008-09-02|    2914|541000|       house|       4|     601500.0|\n",
      "|2008-09-05|    2914|395000|       house|       3|     560200.0|\n",
      "|2008-09-05|    2914|552000|       house|       4|    558833.33|\n",
      "|2008-09-17|    2914|410000|       house|       3|    537571.43|\n",
      "|2008-09-26|    2914|755000|       house|       4|     564750.0|\n",
      "|2008-10-14|    2914|420000|       house|       4|    548666.67|\n",
      "|2008-10-16|    2914|375000|       house|       3|     531300.0|\n",
      "|2008-10-21|    2914|515000|       house|       4|    529818.18|\n",
      "|2008-10-27|    2914|440000|       house|       3|    497090.91|\n",
      "|2008-10-27|    2914|475000|       house|       4|    485727.27|\n",
      "|2008-11-05|    2914|477500|       house|       4|    486863.64|\n",
      "|2008-11-18|    2914|540000|       house|       4|    486772.73|\n",
      "|2008-12-06|    2914|600000|       house|       4|    505409.09|\n",
      "|2008-12-22|    2914|456000|       house|       3|    496681.82|\n",
      "|2008-12-23|    2914|444000|       house|       4|    499772.73|\n",
      "|2008-12-24|    2914|400000|       house|       4|     467500.0|\n",
      "|2009-01-08|    2914|410000|       house|       4|    466590.91|\n",
      "+----------+--------+------+------------+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "windSpec = Window.partitionBy('postcode').orderBy('datesold').rowsBetween(-10, Window.currentRow)\n",
    "df.withColumn('avg_pr_before', F.round(F.avg('price').over(windSpec), 2)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+------------+--------+------------+\n",
      "|  datesold|postcode| price|propertyType|bedrooms|avg_pr_after|\n",
      "+----------+--------+------+------------+--------+------------+\n",
      "|2007-07-02|    2914|800000|       house|       5|   529818.18|\n",
      "|2008-06-17|    2914|600000|       house|       4|   497090.91|\n",
      "|2008-08-29|    2914|465000|       house|       4|   485727.27|\n",
      "|2008-09-02|    2914|541000|       house|       4|   486863.64|\n",
      "|2008-09-05|    2914|395000|       house|       3|   486772.73|\n",
      "|2008-09-05|    2914|552000|       house|       4|   505409.09|\n",
      "|2008-09-17|    2914|410000|       house|       3|   496681.82|\n",
      "|2008-09-26|    2914|755000|       house|       4|   499772.73|\n",
      "|2008-10-14|    2914|420000|       house|       4|    467500.0|\n",
      "|2008-10-16|    2914|375000|       house|       3|   466590.91|\n",
      "|2008-10-21|    2914|515000|       house|       4|   483409.09|\n",
      "|2008-10-27|    2914|440000|       house|       3|   489772.73|\n",
      "|2008-10-27|    2914|475000|       house|       4|   507045.45|\n",
      "|2008-11-05|    2914|477500|       house|       4|   532045.45|\n",
      "|2008-11-18|    2914|540000|       house|       4|    525000.0|\n",
      "|2008-12-06|    2914|600000|       house|       4|   516818.18|\n",
      "|2008-12-22|    2914|456000|       house|       3|    510000.0|\n",
      "|2008-12-23|    2914|444000|       house|       4|   511090.91|\n",
      "|2008-12-24|    2914|400000|       house|       4|   510272.73|\n",
      "|2009-01-08|    2914|410000|       house|       4|   506181.82|\n",
      "+----------+--------+------+------------+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windSpec = Window.partitionBy('postcode').orderBy('datesold').rowsBetween(Window.currentRow, 10)\n",
    "df.withColumn('avg_pr_after', F.round(F.avg('price').over(windSpec), 2)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "windSpec = Window.partitionBy('postcode').orderBy('datesold').rowsBetween(Window.currentRow, Window.unboundedFollowing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoKJ_YOBUQGL"
   },
   "source": [
    "## Задание 2\n",
    "Найдите среднюю цену жилья для каждого года и приджойните эти данные к таблице из задания 1. (2 балла)\n",
    "\n",
    "\n",
    "*(left join on a.year(date of sale) = b.year, где a - таблица из первого задания, а b таблица после группировки)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "emn6tIDVQWi-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 74:===================================================>    (69 + 2) / 75]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+\n",
      "|year(datesold)|avg_price|\n",
      "+--------------+---------+\n",
      "|          2007|522377.21|\n",
      "|          2018|660701.04|\n",
      "|          2015|626101.34|\n",
      "|          2013| 553416.3|\n",
      "|          2014|592653.76|\n",
      "|          2019|634184.22|\n",
      "|          2012|552501.37|\n",
      "|          2009|496092.03|\n",
      "|          2016|635185.31|\n",
      "|          2010|559564.81|\n",
      "|          2011|566715.11|\n",
      "|          2008|493814.16|\n",
      "|          2017|671880.55|\n",
      "+--------------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_year_price = df.groupBy(F.year('datesold')).agg(F.round(F.avg(F.col('price')), 2).alias('avg_price'))\n",
    "df_year_price.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qvh2x6_8YU3F"
   },
   "source": [
    "## Задание 3\n",
    "В итоге у вас таблица с колонками (или нечто похожее):\n",
    "*   price\n",
    "*   Среднегодовая цена\n",
    "*  Средняя стомость 10 проданных домов до текущего в том же районе (4digit postcode) (1 балл)\n",
    "*  Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode) (1 балл)\n",
    "*  Стоимость последнего проданного дома до текущего ((1 балл)\n",
    "*  и др.\n",
    "\n",
    "Посчитайте кол-во уникальных значений в каждой строчке (unique(row)). (2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFBmC9gvNyzl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Урок 5. HW. wf_udf_joins",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
